{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1REHdIWhR-Er",
    "outputId": "666a1f62-7898-4231-81c0-222844b55c51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n",
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "colab_type": "code",
    "id": "c9a8mWckSYsj",
    "outputId": "53653258-9a7f-4d03-a768-3e58d562ef1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-serving-client\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/09/aae1405378a848b2e87769ad89a43d6d71978c4e15534ca48e82e723a72f/bert_serving_client-1.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bert-serving-client) (1.18.3)\n",
      "Requirement already satisfied: pyzmq>=17.1.0 in /usr/local/lib/python3.6/dist-packages (from bert-serving-client) (19.0.0)\n",
      "Installing collected packages: bert-serving-client\n",
      "Successfully installed bert-serving-client-1.10.0\n",
      "Collecting bert-serving-server[http]\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/bd/cab677bbd0c5fb08b72e468371d2bca6ed9507785739b4656b0b5470d90b/bert_serving_server-1.10.0-py3-none-any.whl (61kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 8.9MB/s \n",
      "\u001b[?25hCollecting GPUtil>=1.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.18.3)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=17.1.0 in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (19.0.0)\n",
      "Requirement already satisfied, skipping upgrade: flask; extra == \"http\" in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.1.2)\n",
      "Collecting flask-compress; extra == \"http\"\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/96/cd684c1ffe97b513303b5bfd4bbfb4114c5f4a5ea8a737af6fd813273df8/Flask-Compress-1.5.0.tar.gz\n",
      "Collecting flask-json; extra == \"http\"\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/2d/4c21d98b11f3a206fabbdd965b53a2ca3ee9fab7646c93cf36c060e8f1a4/Flask_JSON-0.3.4-py3-none-any.whl\n",
      "Collecting flask-cors; extra == \"http\"\n",
      "  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: bert-serving-client; extra == \"http\" in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (2.11.2)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (1.0.1)\n",
      "Collecting brotli\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/68/60a220454dc5083c6d59b41aa90bb1c96fad62a0abf3a33e0ef64b38638a/Brotli-1.0.7-cp36-cp36m-manylinux1_x86_64.whl (352kB)\n",
      "\u001b[K     |████████████████████████████████| 358kB 18.3MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask; extra == \"http\"->bert-serving-server[http]) (1.1.1)\n",
      "Building wheels for collected packages: GPUtil, flask-compress\n",
      "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=4ac4993701f79f5a73c8465a24af6478a1bb163d5f6f2c1da1500fd705a7697b\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
      "  Building wheel for flask-compress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for flask-compress: filename=Flask_Compress-1.5.0-cp36-none-any.whl size=5273 sha256=31202a19ee3fa8249f5e5327b0dd5e3e0ca10930b39355569ca4a901605ae050\n",
      "  Stored in directory: /root/.cache/pip/wheels/f7/e9/e4/5afc286be7c87461375e33152558415dfeb0c8f5af3b50e742\n",
      "Successfully built GPUtil flask-compress\n",
      "Installing collected packages: GPUtil, brotli, flask-compress, flask-json, flask-cors, bert-serving-server\n",
      "Successfully installed GPUtil-1.4.0 bert-serving-server-1.10.0 brotli-1.0.7 flask-compress-1.5.0 flask-cors-3.0.8 flask-json-0.3.4\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-serving-client\n",
    "!pip install -U bert-serving-server[http]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "Jxi5hT0Cpbxv",
    "outputId": "5a4e397e-f925-40ea-d19d-87cab9f95f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-30 03:32:47--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.14.112, 2607:f8b0:4007:802::2010\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.14.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 407727028 (389M) [application/zip]\n",
      "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
      "\n",
      "uncased_L-12_H-768_ 100%[===================>] 388.84M  99.4MB/s    in 3.9s    \n",
      "\n",
      "2020-04-30 03:32:51 (99.4 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
      "\n",
      "Archive:  uncased_L-12_H-768_A-12.zip\n",
      "   creating: uncased_L-12_H-768_A-12/\n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "!unzip uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFQTa4V0S9qV"
   },
   "outputs": [],
   "source": [
    "!nohup bert-serving-start -max_seq_len NONE -pooling_strategy NONE -num_worker=4 -model_dir=./uncased_L-12_H-768_A-12 > out.file 2>&1 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S60dO2hDS_xS"
   },
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9L9rwSHjTKfX"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9XgWk9HHrBHH"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format},threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDxuxiMtw045"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()\n",
    "os.chdir(r'/content/reddit')\n",
    "f1=open('/content/BERT_Vocabulary.txt', 'r', encoding=\"utf8\").read()\n",
    "for fileName in Path('.').glob('*.txt'):\n",
    "  f=open(str(fileName.absolute()),'r',encoding='utf-8').read().split(\" \")\n",
    "  a=str(fileName)\n",
    "  f2=open(\"/content/out.txt\",\"a+\")\n",
    "  for i in f:\n",
    "    if \"wiki_\" in i.lower():\n",
    "      x=i.rpartition(\"__\")[0].replace(\"Wiki__\",\"\").replace(\"_\",\" \").lower().strip()\n",
    "      if x=='':\n",
    "        break\n",
    "      for p in x:\n",
    "        if p==\" \":\n",
    "          break\n",
    "      if p!=\" \":\n",
    "        if x in f1:\n",
    "          vec=bc.encode([x])\n",
    "          c=str(vec.argmax())\n",
    "          f2.write(a+','+x+','+c+'\\n')\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4wJuKq9W5HJ6"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(r'/content/reddit')\n",
    "\n",
    "def search(target, text, context=9):\n",
    "    words = re.findall(r'\\w+', text)\n",
    "    matches = (i for (i,w) in enumerate(words) if w.lower() == target)\n",
    "    for index in matches:\n",
    "        if index < context //2:\n",
    "            yield words[0:context+1]\n",
    "        elif index > len(words) - context//2 - 1:\n",
    "            yield words[-(context+1):]\n",
    "        else:\n",
    "            yield words[index - context//2:index + context//2 + 1]\n",
    "\n",
    "def li(s):  \n",
    "    str = \"\"    \n",
    "    for i in s:\n",
    "      for j in i:  \n",
    "        str += j\n",
    "      str+=' '\n",
    "    return str\n",
    "\n",
    "for fileName in Path('.').glob('*.txt'):\n",
    "  a=str(fileName)\n",
    "  text=open(a,'r',encoding='utf-8').read().lower()\n",
    "  f=open(str(fileName.absolute()),'r',encoding='utf-8').read().split(\" \")\n",
    "  f2=open(\"/content/output.txt\",\"a+\")\n",
    "  for i in f:\n",
    "    if \"wiki_\" in i.lower():\n",
    "      x=i.rpartition(\"__\")[0].replace(\"Wiki__\",\"\").replace(\"_\",\" \").lower().strip()\n",
    "      b=list(search(i.lower(),text))\n",
    "      c=len(b)\n",
    "      for i in range(c):\n",
    "        f2.write(a+','+li(b[i])+','+x+'\\n')\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r2lnA9yg3FhG"
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "\n",
    "os.chdir(r'/content')\n",
    "completed_lines_hash = set()\n",
    "f1=open(\"output.txt\", \"r\")\n",
    "f2=open(\"output_no_duplicates.txt\", \"w\")\n",
    "\n",
    "for line in f1:\n",
    "  \n",
    "  hashValue = hashlib.md5(line.rstrip().encode('utf-8')).hexdigest()\n",
    "  \n",
    "  if hashValue not in completed_lines_hash:\n",
    "    f2.write(line)\n",
    "    completed_lines_hash.add(hashValue)\n",
    "f1.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUnnVfzz5CCv"
   },
   "outputs": [],
   "source": [
    "f1=open('output_no_duplicates.txt','r')\n",
    "f2=open('BERT_Vocabulary.txt','r').read()\n",
    "f3=open('output_single_compared.txt','w')\n",
    "for i in f1:\n",
    "  a=i.split(',')[0].strip()\n",
    "  b=i.split(',')[1].strip()\n",
    "  c=i.split(',')[2].strip()\n",
    "  if len(c.split())==1:\n",
    "    if c in f2:\n",
    "      f3.write(a+','+b+','+c+'\\n')\n",
    "f1.close()\n",
    "f3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "waPZGqwLAF6_"
   },
   "outputs": [],
   "source": [
    "f1=open('output_single_compared.txt','r')\n",
    "f2=open('output_single_compared_sort.txt','w')\n",
    "a=sorted(f1)\n",
    "s=\"\"\n",
    "for i in a:\n",
    "    s += i\n",
    "f2.write(s)\n",
    "f1.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0NlvNRE2A_qO"
   },
   "outputs": [],
   "source": [
    "f1=open('output_single_compared_sort.txt','r')\n",
    "f2=open('output_clean.txt','w')\n",
    "\n",
    "def li(s):  \n",
    "    str = \"\"    \n",
    "    for i in s:\n",
    "      for j in i:  \n",
    "        str += j\n",
    "      str+=' '\n",
    "    return str\n",
    "\n",
    "for i in f1:\n",
    "  z=0\n",
    "  a=i.split(',')[0].strip()\n",
    "  b=i.split(',')[1].strip()\n",
    "  c=i.split(',')[2].strip()\n",
    "  b=b.split()\n",
    "  for j in b:\n",
    "    if \"wiki_\" in j.lower():\n",
    "      x=j.rpartition(\"__\")[0].replace(\"wiki__\",\"\").replace(\"_\",\" \").lower().strip()\n",
    "      b[z]=x\n",
    "    z+=1\n",
    "  f2.write(a+','+li(b)+','+c+'\\n')\n",
    "f1.close()\n",
    "f2.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
